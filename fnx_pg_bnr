#!/usr/local/sbin/suid-python
from __future__ import print_function
# from __future__ import print_function, unicode_literals

from dbf import Date
from antipathy import Path
from scription import *
from tempfile import mkdtemp
import os
import pwd
import re
import time

settings = IniFile('/etc/openerp/fnx.ini', section='postgres')
PSQLCMD = '%(psql)s %%(port)s' % settings
PGDUMPCMD = '%(pg_dump)s %%(port)s --file=%%(filename)s %%(db)s' % settings
PGDUMPALLCMD = '%(pg_dumpall)s %%(port)s --file=%%(filename)s --globals-only' % settings
DAILY_STORAGE = Path(settings.daily)
MONTHLY_STORAGE = Path(settings.monthly)
DAILY_LIMIT = settings.daily_limit
MONTHLY_LIMIT = settings.monthly_limit
TARARCHIVE = '%(tar)s --create --gzip --file %%(target_name)s %%(file_list)s' % settings
TARDISPLAY = '%(tar)s --list --file %%(target)s' % settings
TGZEXTRACT = '%(tar)s --file %%(archive)s --extract %%(target)s' % settings
COMPRESS = '%(gzip)s --force --rsyncable %%(target_name)s' % settings

TODAY = Date.today()
POSTGRES_IDS = tuple(pwd.getpwnam('postgres')[2:4])
ACTUAL_IDS = os.getuid(), os.getgid()
TEMP = None
PORT = None


@Script(
        rescue=('ignore checks', FLAG),
        )
def main():
    print('  main::0', verbose=2)
    global START_DIR, TEMP, RESCUE
    RESCUE = rescue
    if not rescue:
        if not DAILY_STORAGE.exists():
            raise SystemExit('%s needs to be created, and owned by postgres' % DAILY_STORAGE)
        if not MONTHLY_STORAGE.exists():
            raise SystemExit('%s needs to be created, and owned by postgres' % MONTHLY_STORAGE)
    START_DIR = Path.getcwd()
    _get_pg_port()
    print('  main::1', verbose=2)
    try:
        with user_ids(*POSTGRES_IDS):
            print('  main::2', verbose=2)
            TEMP = Path(mkdtemp(dir=unicode('/tmp'), suffix='_pgdbs'))
        script_command()
        print('finished')
    finally:
        print('  main::3', verbose=2)
        if TEMP:
            TEMP.rmtree()
        print('  main::4', verbose=2)
        START_DIR.chdir()


@Command(
        dbs=('database(s) to backup [default: all dbs]', MULTI),
        id=('extra info for extra backups (appears in compressed file name)', OPTION),
        dst=('where to put backup', OPTION, Path, None),
        )
def backup(dbs, id, dst):
    """
    backs up all postgres databases, roles, etc., or single databases
    """
    print('  backup::0', verbose=2)
    print('  backup::1', verbose=2)
    everything = not bool(dbs)
    print('backing up everything?', everything)
    with user_ids(*POSTGRES_IDS):
        print('backup::', verbose=2)
        TEMP.chdir()
        if not dbs and not RESCUE and not dst:
            print('  backup::2', verbose=2)
            store = True
            storage = DAILY_STORAGE
            dbs = _get_dbs_from_postgres()
        else:
            print('  backup::3', verbose=2)
            store = False
            storage = TEMP
            if RESCUE and not dbs:
                dbs = _get_dbs_from_postgres()
        template = '%s.sql'
        failures = False
        # first, backup as many databases as we can
        print('backing up: ', end=' ')
        for db in dbs:
            print(db, end=' ')
            file = template % db
            if not _backup(db, file) and not db.startswith('template'):
                failures = True
        print()
        if everything:
            # if everything, get globals options...
            pg_dumpall = PGDUMPALLCMD % dict(filename=TEMP/'_roles_etc.sql', port=PORT)
            print('   roles, etc.', end='')
            result = Execute(pg_dumpall, pty=False)
            if result.returncode:
                print(' -- FAILED', file=stderr)
            else:
                print()
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    print('   %s' % line)
            if result.returncode:
                print('       %s' % pg_dump, file=stderr)
                for line in result.stderr.split('\n'):
                    print('      %s' % line, file=stderr)
                print()
                failures = True

    # wait an extra few seconds to give tar file time to show up
    # (keep getting sporadic errors at Falcon)
    time.sleep(5)
    # postgres is backed up, revert to root privilege
    # then, combine them all into a single tar.gz file
    print('  backup::4', verbose=2)
    tgz_file = _tgz(TEMP, storage, id)
    # finally, make a copy in monthly if today is the first
    # but only if store == True
    if store:
        if TODAY.day == 1:
            print('  backup::5', verbose=2)
            tgz_file.copy(MONTHLY_STORAGE)
            print('  backup::6', verbose=2)
        _remove_excess(DAILY_STORAGE, DAILY_LIMIT)
        _remove_excess(MONTHLY_STORAGE, MONTHLY_LIMIT)
    else:
        print('  backup::7', verbose=2)
        tgz_file.chown(*ACTUAL_IDS)
        print('  backup::8', verbose=2)
        tgz_file.copy(dst or START_DIR)
    if failures:
        raise SystemExit('not all databases backed up')


@Command()
def dbs():
    print('databases available: ', ', '.join(_get_dbs_from_postgres()), verbose=0)


@Command(
        date=Spec('date of archive file', OPTION, None, Date),
        dbs=Spec('names of dbs to extract [default: all]', MULTI, None),
        file=Spec('archive file to extract from', OPTION, None, Path),
        )
def extract(date, dbs, file):
    print('  extract::0', verbose=2)
    if date and file:
        abort('only one of DATE and FILE may be specified')
    if not (date or file):
        abort('must have one of DATE or FILE')
    if date:
        print('  extract::1', verbose=2)
        found = DAILY_STORAGE.glob('%s*' % date)
        if not found:
            print('  extract::2', verbose=2)
            found = MONTHLY_STORAGE.glob('%s*' % date)
            if not found:
                raise ValueError('no files found for %s' % date)
        if len(found) > 1:
            raise ValueError('should only have one match, but found %s' % ', '.join(found))
        [file] = found
    print(file)
    if not dbs:
        dbs = _list(file)
    extracted = []
    for db in dbs:
        print('   %s' % db)
        sql_file = _extract(db, file)
        extracted.append(sql_file)
    with user_ids(0, 0):
        print('  extract::3', verbose=2)
        for file in extracted:
            file.chown(*ACTUAL_IDS)


@Command(
        date=('date of archive to list', OPTION, 'd', Date),
        file=('archive file to list', OPTION, 'f', Path),
        daily=('show all daily backups', FLAG, None),
        monthly=('show all monthly backups', FLAG),
        )
def list(date, file, daily, monthly):
    """
    show all tables archived for DATE, or stored in FILE
    """
    print('  list::0', verbose=2)
    if sum(1 for p in [date, file, daily, monthly] if p) != 1:
        help('at least one (and only one) of DATE, FILE, DAILY, and MONTHLY may be specified')
    if daily:
        print('  list::1', verbose=2)
        for file in sorted(DAILY_STORAGE.glob('*')):
            print(file, verbose=0)
    elif monthly:
        print('  list::2', verbose=2)
        for file in sorted(MONTHLY_STORAGE.glob('*')):
            print(file, verbose=0)
    else:
        print('  list::3', verbose=2)
        if date:
            found = DAILY_STORAGE.glob('%s*' % date)
            if not found:
                print('  list::4', verbose=2)
                found = MONTHLY_STORAGE.glob('%s*' % date)
                if not found:
                    abort('no files found for %s' % date)
            if len(found) > 1:
                abort('should only have one match, but found %s' % ', '.join(found))
            [file] = found
        print('  list::5', verbose=2)
        print(file)
        db_names = _list(file)
        for name in db_names:
            print('   %s' % name, verbose=0)
        print()
        print('  list::6', verbose=2)


@Command(
        date=('date of archive to restore from', OPTION, None, Date),
        db=('database in archive to restore', OPTION, None),
        file=('archive file to extract from / sql file to restore from', OPTION, None, Path),
        new_db=('restore as a new database [default: restore to same database]', OPTION, None),
        all_dbs=('restore all databases found in backup', FLAG, None),
        )
def restore(db, date, file, new_db, all_dbs):
    print('  restore::0', verbose=2)
    if db and not _user_exists('openerp') and not RESCUE:
        abort('missing openerp user in postgresql, aborting restore [use --resuce to override]')
    all_db_names = []
    all_sql_files = []
    if date and file:
        raise ValueError('only one of DATE and FILE may be specified')
    # if file and not (name or new_db):
    #     raise ValueError('either NAME or NEW_DB must be specified with FILE')
    tgz_file = sql_file = None
    if date:
        print('  restore::1', verbose=2)
        found = DAILY_STORAGE.glob('%s*' % date)
        if not found:
            print('  restore::2', verbose=2)
            found = MONTHLY_STORAGE.glob('%s*' % date)
            if not found:
                raise ValueError('no files found for %s' % date)
        if len(found) > 1:
            raise ValueError('should only have one match, but found %s' % ', '.join(found))
        [file] = found
    if file:
        print('  restore::3', verbose=2)
        # if a file is specified copy it to TEMP
        file.copy(TEMP)
        file = TEMP/file.filename
        file.chown(*POSTGRES_IDS)
        if file.ext in ('.tar', '.gz', '.tgz'):
            tgz_file = file
            all_db_names = _list(tgz_file)
        else:
            sql_file = file
            if db is None:
                db = _db_name_from_file(sql_file)
    print('  restore::4', verbose=2)
    with user_ids(*POSTGRES_IDS):
        print('  restore::5', verbose=2)
        TEMP.chdir()
        print('  sql_file: %s\n  tgz_file: %s' % (sql_file, tgz_file), verbose=2)
        if tgz_file:
            print('  restore::6', verbose=2)
            # at this point, we have the archive file, and we have the
            # name(s) of the database to extract in db or all_db_names
            if db:
                print('  restore::7', verbose=2)
                sql_file = _extract(db, tgz_file)
            else:
                print('  restore::8', verbose=2)
                print('extracting sql files...')
                for _db in all_db_names:
                    all_sql_files.append(_extract(_db, tgz_file))
        # we now have sql file(s) to restore from
        if all_dbs:
            # restore everything
            _restore_all_dbs(all_sql_files, all_db_names)
        else:
            # restore single database
            _restore_single_db(sql_file, db, new_db)


def _backup(db, filename):
    pg_dump = PGDUMPCMD % dict(filename=TEMP/filename, db=db, port=PORT)
    print('   %s' % db, end='')
    result = Execute(pg_dump, pty=False)
    if result.returncode:
        print(' -- FAILED', file=stderr)
    else:
        print()
    if result.stdout:
        for line in result.stdout.strip().split('\n'):
            print('   %s' % line)
    if result.returncode:
        print('       %s' % pg_dump, file=stderr)
        for line in result.stderr.split('\n'):
            print('      %s' % line, file=stderr)
        print()
    return not result.returncode

def _db_name_from_file(filename, datestr=None):
    print('  _db_name_from_file::0', verbose=2)
    print('  checking', filename, 'for datestr %r' % datestr, verbose=2)
    if datestr is None:
        # probably an sql filename
        return re.sub('\d{4}-\d{1,2}-\d{1,2}_', '', filename.split('.')[0])
    if filename.startswith(datestr):
        # old style with leading date and '_pg91.sql' trailer
        db_name = filename[11:].rsplit('_', 1)[0].strip()
    else:
        # new style with .sql trailer
        db_name = filename[:-4]
    return db_name

def _extract(name, archive):
    print('_extract::0', verbose=2)
    date = archive.filename[:10]
    deprecated_name = '%s_%s_pg91.sql' % (date, name)
    name = name + '.sql'
    print('_extract::1', verbose=2)
    for target in (name, deprecated_name):
        print('_extract::2', verbose=2)
        tgz_cmd = TGZEXTRACT % dict(archive=archive, target=target)
        result = Execute(tgz_cmd, pty=False)
        if result.returncode == 0:
            print('  %s extracted' % target, verbose=2)
            break
    else:
        print('_extract::3', verbose=2)
        if result.stdout:
            for line in result.stdout.strip().split('\n'):
                print(line)
        print('return code:', result.returncode, file=stderr)
        for line in result.stderr.split('\n'):
            print(line, file=stderr)
        raise SystemExit(result.returncode)
    print('_extract::4', verbose=2)
    return Path(target)

def _get_dbs_from_postgres():
    result = _psql('--list --tuple')
    dbs = []
    for line in result.split('\n'):
        db = line.split('|', 1)[0].strip()
        if db and db != 'template0':
            # template0 is special, and cannot be accessed
            dbs.append(db)
    if not dbs:
        print('FAILED: %s' % psql, file=stderr)
        raise SystemExit('no databases found!')
    return dbs

def _get_dbs_from_tar(tar_file):
    result = _psql('--list --tuple')
    dbs = []
    for line in result.split('\n'):
        db = line.split('|', 1)[0].strip()
        if db and db != 'template0':
            # template0 is special, and cannot be accessed
            dbs.append(db)
    if not dbs:
        print('FAILED: %s' % psql, file=stderr)
        raise SystemExit('no databases found!')
    return dbs

def _get_pg_port():
    global PORT, PSQLCMD
    if PORT is not None:
        return
    with user_ids(0, 0):
        etc_oe = Path('/etc/openerp')
        if etc_oe.exists('server.conf'):
            conf = etc_oe/'server.conf'
        elif etc_oe.exists('openerp-server.conf'):
            conf = etc_oe/'openerp-server.conf'
        else:
            raise ValueError('unable to find OpenERP configuration file')
        with conf.open() as conf:
            for line in conf.readlines():
                if line.startswith('db_port'):
                    port = line.split('=')[1].strip()
                    if port == 'False':
                        PORT = ''
                    else:
                        PORT = '-p %d' % int(port)
        PSQLCMD = (PSQLCMD % dict(port=PORT)).strip()

def _list(archive):
    print('  _list::1', verbose=2)
    print('checking archive', archive.filename)
    datestr = archive.filename[:11]
    tgz_cmd = TARDISPLAY % dict(target=archive)
    result = Execute(tgz_cmd, pty=False)
    dbs = []
    if result.stdout:
        for line in result.stdout.strip().split('\n'):
            db_name = _db_name_from_file(line, datestr)
            if db_name:
                dbs.append(db_name)
    if result.returncode:
        print('FAILED: %s' % tgz_cmd, file=stderr)
        for line in result.stderr.split('\n'):
            print('   %s' % line, file=stderr)
        raise SystemExit(result.returncode)
    print('  found: ', ', '.join(dbs))
    return dbs

def _psql(cmd):
    cmd = '%s %s' % (PSQLCMD, cmd)
    print(verbose=2)
    print(cmd, verbose=2)
    with user_ids(*POSTGRES_IDS):
        result = Execute(cmd, pty=False)
    if result.returncode:
        lines = []
        if result.returncode != -1:
            lines.append('FAILED: <%d> %s' % (result.returncode, cmd))
        for line in result.stderr.split('\n'):
            lines.append('   %s' % line)
        if result.returncode != -1:
            raise Exception('\n'.join(lines))
    return result.stdout

def _remove_excess(storage, limit):
    """
    keep LIMIT days worth of our backups
    """
    try:
        found = storage.glob('*_pg91.tar.gz')
        found.sort(reverse=True)
        for target in found[limit:]:
            target.remove()
    except:
        print(sys.exc_info(), file=stderr)
        raise

def _restore_all_dbs(sql_files, dbs):
    print('  _restore_all::0', verbose=2)
    if len(sql_files) != len(dbs):
        print('sql files:\n  ', '\n   '.join(sql_files), file=stderr)
        print('db names:\n  ', '\n   '.join(dbs), file=stderr)
        abort('number of files vs number of databases differ')
    print('  _restore_all::1', verbose=2)
    for db in dbs:
        # some databases cannot be dropped
        if db in ('_roles_etc', 'postgres', 'template1'):
            continue
        print('dropping', db)
        _psql('-c "DROP DATABASE IF EXISTS %s;"' % db)
    log_file = Path('restore_all.log')
    print('  _restore_all::3', verbose=2)
    print('restoring globals... ', end='')
    _psql('--log-file %s --echo-all --file _roles_etc.sql' % log_file)
    print('success\nrestoring postgres... ', end='')
    postgres_file = sql_files[dbs.index('postgres')]
    if 'postgres' not in postgres_file:
        abort('\nlogic error: "postgres" table not in "%s"' % postgres_file)
    _psql('--log-file %s --echo-all --file %s postgres' % (log_file, postgres_file))
    print('sucess\nrestoring template1... ', end='')
    template1_file = sql_files[dbs.index('template1')]
    if 'template1' not in template1_file:
        abort('\nlogic error: "template1" table not in "%s"' % template1_file)
    _psql('--log-file %s --echo-all --file %s template1' % (log_file, template1_file))
    print('success')
    errors = []
    for db, sql_file in zip(dbs, sql_files):
        if db in ('_roles_etc', 'template1', 'postgres'):
            continue
        print('restoring %s... ' % db, end='')
        _psql('''-c "CREATE DATABASE %s TEMPLATE template1 ENCODING 'unicode';"''' % db)
        try:
            error = None
            print('  _restore_all::4', verbose=2)
            _psql(
                    '--log-file %(log)s --echo-all --file %(sql)s %(db_name)s'
                    % dict(sql=sql_file, db_name=db, log=log_file),
                    )
            print('  _restore_all::5', verbose=2)
            # TODO: find out if changing the owner is necessary
            _psql('-c "ALTER DATABASE %s OWNER TO openerp;"' % db)
        except Exception, exc:
            print('FAILED')
            errors.append(exc)
        else:
            print('success')
    with user_ids(0, 0):
        print('  _restore_all::6', verbose=2)
        dest_file = START_DIR/log_file.filename
        if dest_file.exists():
            print('  _restore_all::7', verbose=2)
            dest_file.remove()
        print('  _restore_all::8', verbose=2)
        log_file.chown(*ACTUAL_IDS)
        print('  _restore_all::9', verbose=2)
        log_file.move(dest_file)
    if errors:
        print('\nerrors', file=stderr)
        for error in errors:
            print('------', file=stderr)
            print(error, file=stderr)
        print('------', file=stderr)
        abort('errors encountered')
        # possibly examine the log file for errors here

def _restore_single_db(sql_file, db, new_db):
    if new_db is None:
        new_db = db
    if not new_db.startswith('test_'):
        print('  _restore_single::1', verbose=2)
        current_dbs = _get_dbs_from_postgres()
        if new_db in current_dbs:
            answer = get_response('\n%s already exists -- [r]ename or [o]verwrite?' % new_db)
            if answer == 'overwrite':
                if not get_response('\nthis cannot be undone -- are you sure?'):
                    raise SystemExit('database restore aborted')
                # drop...
                _psql('-c "DROP DATABASE %s;"' % new_db)
            elif answer == 'rename':
                print('\ncurrent databases:', verbose=0)
                for db in current_dbs:
                    print('  ', db, verbose=0)
                new_name = get_response(
                        '\nnew database name:',
                        validate=lambda name: name not in current_dbs,
                        type=lambda name: name,
                        retry='that name is also in use, please choose another',
                        )
                # rename...
                _psql('-c "ALTER DATABASE %s RENAME TO %s;"' % (new_db, new_name))
            else:
                raise Exception('unable to process response of %r' % answer)
    else:
        print('  _restore_single::2', verbose=2)
        # overwrite test_ databases
        _psql('-c "DROP DATABASE IF EXISTS %s;"' % new_db)
    # at this point we are good to restore...
    #
    # (re)create the new database
    log_file = Path(new_db+'.log')
    print('  _restore_single::3', verbose=2)
    _psql('''-c "CREATE DATABASE %s TEMPLATE template1 ENCODING 'unicode';"''' % new_db)
    try:
        error = None
        print('  _restore_single::4', verbose=2)
        _psql(
                '--log-file %(log)s --echo-all --file %(sql)s %(db_name)s'
                % dict(sql=sql_file, db_name=new_db, log=log_file),
                )
        print('  _restore_single::5', verbose=2)
        _psql('-c "ALTER DATABASE %s OWNER TO openerp;"' % new_db)
    except Exception, exc:
        error = exc
    with user_ids(0, 0):
        print('  _restore_single::6', verbose=2)
        dest_file = START_DIR/new_db+'.log'
        if dest_file.exists():
            print('  _restore_single::7', verbose=2)
            dest_file.remove()
        print('  _restore_single::8', verbose=2)
        log_file.chown(*ACTUAL_IDS)
        print('  _restore_single::9', verbose=2)
        log_file.move(dest_file)
    if error:
        raise error
    # possibly examine the log file for errors here

def _tgz(source_path, target_path, id=None):
    if id is None:
        target = target_path/'%s_pg91.tar.gz' % TODAY
    else:
        target = target_path/'%s_%s_pg91.tar.gz' % (TODAY, id)
    tgz_cmd = TARARCHIVE % dict(target_name=target, file_list=' '.join(source_path.listdir()))
    print('\narchiving . . .')
    result = Execute(tgz_cmd, cwd=source_path, pty=False, GZIP="--rsyncable")
    if result.stdout:
        for line in result.stdout.split('\n'):
            print('   %s' % line)
    if result.returncode:
        print('FAILED: %s' % tgz_cmd, file=stderr)
        for line in result.stderr.split('\n'):
            print('        %s' % line, file=stderr)
        raise SystemExit(result.returncode)
    print('\ncompressing . . .')
    return target

def _user_exists(user):
    output = _psql('-c "select rolname from pg_authid;"').split('\n')
    result = False
    for i, line in enumerate(output[2:], start=1):
        print(i, line)
        if line.strip() == user:
            result = True
    return result

Main()
