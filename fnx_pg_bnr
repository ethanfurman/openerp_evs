#!/usr/local/bin/suid-python --virtualenv
"""
Create, list, and restore OpenERP databases.

Must be run as root
"""
from __future__ import print_function
from aenum import Enum
from dbf import Date
from antipathy import Path
from scription import *
from tempfile import mkdtemp
from openerplib import get_connection, get_records
import os
import pwd
import re
import sys
import time

# globals

VIRTUAL_ENV = Path(os.environ['VIRTUAL_ENV'])
CONFIG_DIR = VIRTUAL_ENV / 'config'
VAR_OPENERP_DIR = VIRTUAL_ENV / 'var/openerp'
pg_settings = IniFile(CONFIG_DIR / 'fnx.ini', section='postgres')
server_config = IniFile(CONFIG_DIR / 'server.conf', section='options', plain=True)
PGHOST = server_config.db_host
PGPORT = server_config.db_port
PGDATA = server_config.db_name
PGUSER = server_config.db_user
PGPSWD = server_config.db_password
PSQLCMD = '%(psql)s' % pg_settings
PGDUMPCMD = '%(pg_dump)s'
PGDUMPALLCMD = '%(pg_dumpall)s'
if PGHOST:
    PSQLCMD += ' -h %s' % PGHOST
    PGDUMPCMD += ' -h %s' % PGHOST
    PGDUMPALLCMD += ' -h %s' % PGHOST
if PGPORT:
    PSQLCMD += ' -p %s' % PGPORT
    PGDUMPCMD += ' -p %s' % PGPORT
    PGDUMPALLCMD += ' -p %s' % PGPORT
PGDUMPCMD += ' --file=%%(filename)s %%(db)s'
PGDUMPALLCMD += ' --file=%%(filename)s --globals-only'
STORAGE_1 = Path(pg_settings.storage1)
STORAGE_2 = Path(pg_settings.storage2)
TARARCHIVE = '%(tar)s --create --gzip --file %%(target_name)s %%(file_list)s' % pg_settings
TARFILEARCHIVE = '%(tar)s --create --file %%(target_name)s %%(file_list)s' % pg_settings
TARDISPLAY = '%(tar)s --list --file %%(target)s' % pg_settings
TGZEXTRACT = '%(tar)s --file %%(archive)s --extract %%(target)s' % pg_settings
UNTAR = '%(tar)s -C %%(root_dir)s -xf %%(archive)s' % pg_settings
COMPRESS = '%(gzip)s --force --rsyncable %%(target_name)s' % pg_settings
oe_settings = IniFile(CONFIG_DIR / 'fnx.ini', section='openerp')
OEHOST = oe_settings.host
OEUSER = oe_settings.user
OEDATA = oe_settings.db
OEPSWD = oe_settings.pw

TODAY = Date.today()
POSTGRES_IDS = tuple(pwd.getpwnam('postgres')[2:4])
OPENERP_IDS = tuple(pwd.getpwnam('openerp')[2:4])
ACTUAL_IDS = os.getuid(), os.getgid()
TEMP = None
## PORT = None

# API
@Script(
        rescue=('ignore checks', FLAG),
        )
def main(rescue):
    print('  main::0', verbose=2)
    print('  __file__ =', __file__, verbose=2)
    print('  virtual_env', VIRTUAL_ENV, verbose=2)
    print('  user ids', ACTUAL_IDS)
    #
    if ACTUAL_IDS[0] != 0:
        abort("must be run as root")
    #
    global START_DIR, TEMP, RESCUE
    #
    RESCUE = rescue
    #
    if not rescue:
        if not STORAGE_1.exists():
            raise SystemExit('%s needs to be created, and owned by postgres' % STORAGE_1)
        if not STORAGE_2.exists():
            raise SystemExit('%s needs to be created, and owned by postgres' % STORAGE_2)
    START_DIR = Path.getcwd()
    # _get_pg_port()
    print('  main::1', verbose=2)
    try:
        with user_ids(*POSTGRES_IDS):
            print('  main::2', verbose=2)
            TEMP = Path(mkdtemp(dir=unicode('/tmp'), suffix='_pgdbs'))
        script_command()
        print('finished')
    finally:
        print('  main::3', verbose=2)
        if TEMP:
            TEMP.rmtree()
        print('  main::4', verbose=2)
        START_DIR.chdir()


@Command(
        dbs=('database(s) to backup [default: all dbs]', MULTI),
        id=('extra info for extra backups (appears in compressed file name)', OPTION),
        dst=('where to put backup', OPTION, None, Path),
        files=('include files? [default: True if all dbs]', FLAG, None, Trivalent),
        )
def backup(dbs, id, dst, files):
    """
    backs up all postgres databases, roles, etc., or single databases
    """
    print('  backup::0', verbose=2)
    # get correct pg_dump and pg_dump_all
    _get_dump_cmds()
    print('  backup::1', verbose=2)
    everything = not bool(dbs)
    if files is Unknown:
        files = everything
    print('backing up everything?', everything)
    print('backing up files?', files)
    with user_ids(*POSTGRES_IDS):
        print('backup::', verbose=2)
        TEMP.chdir()
        if not dbs and not RESCUE and not dst:
            print('  backup::2', verbose=2)
            store = True
            dbs_name, files_name = _get_backup_filename()
            dbs = _get_dbs_from_postgres()
        else:
            print('  backup::3', verbose=2)
            store = False
            dbs_name = TEMP
            if RESCUE and not dbs:
                dbs = _get_dbs_from_postgres()
        template = '%s.sql'
        failures = False
        # first, backup as many databases as we can
        print('backing up:')
        for db in dbs:
            file = template % db
            if not _backup(db, file) and not db.startswith('template'):
                failures = True
        print()
        if everything:
            # if everything, get globals options...
            pg_dumpall = PGDUMPALLCMD % dict(filename=TEMP/'_roles_etc.sql')
            print('   roles, etc.', end='')
            result = Execute(pg_dumpall, pty=False)
            if result.returncode:
                print(' -- FAILED', file=stderr)
            else:
                print()
            if result.stdout:
                for line in result.stdout.strip().split('\n'):
                    print('   %s' % line)
            if result.returncode:
                print('       %s' % pg_dumpall, file=stderr)
                for line in result.stderr.split('\n'):
                    print('      %s' % line, file=stderr)
                print()
                failures = True

    # wait an extra few seconds to give tar file time to show up
    # (keep getting sporadic errors at Falcon)
    time.sleep(5)

    # postgres is backed up, revert to root privilege
    # then, combine them all into a single tar.gz file
    print('  backup::4', verbose=2)
    tgz_dbs_file = _tgz_dbs(TEMP, dbs_name, id)
    if files:
        # now get files (must be after dbs or they would be included in the
        # dbs file
        tar_bin_file = _tar_files(files_name, id)
    # finally, make a copy in monthly if today is the first day of the month
    # but only if store == True
    if store:
        _remove_excess(dbs_name)
    else:
        print('  backup::7', verbose=2)
        tgz_dbs_file.chown(*ACTUAL_IDS)
        tgz_dbs_file.copy(dst or START_DIR)
        print('  backup::8', verbose=2)
        if files:
            tar_bin_file.chown(*ACTUAL_IDS)
            tar_bin_file.copy(dst or START_DIR)
    if failures:
        raise SystemExit('not all databases backed up')


@Command()
def dbs():
    "list available databases in postgres"
    print('databases available: ', ', '.join(_get_dbs_from_postgres()), verbose=0)


@Command(
        date=Spec('date of archive file', OPTION, None, Date),
        dbs=Spec('names of dbs to extract [default: all]', MULTI, None),
        file=Spec('archive file to extract from', OPTION, None, Path),
        )
def extract(date, dbs, file):
    print('  extract::0', verbose=2)
    if date and file:
        abort('only one of DATE and FILE may be specified')
    if not (date or file):
        abort('must have one of DATE or FILE')
    if date:
        print('  extract::1', verbose=2)
        found = STORAGE_1.glob('%s*' % date)
        if not found:
            print('  extract::2', verbose=2)
            found = STORAGE_2.glob('%s*' % date)
            if not found:
                raise ValueError('no files found for %s' % date)
        if len(found) > 1:
            raise ValueError('should only have one match, but found %s' % ', '.join(found))
        [file] = found
    print(file)
    if not dbs:
        dbs = _list(file)
    extracted = []
    for db in dbs:
        print('   %s' % db)
        sql_file = _extract(db, file)
        extracted.append(sql_file)
    with user_ids(0, 0):
        print('  extract::3', verbose=2)
        for file in extracted:
            file.chown(*ACTUAL_IDS)


@Command(
        date=Spec('date of archive to list', OPTION, 'd', Date),
        file=Spec('archive file to list', OPTION, 'f', Path),
        )
def list(date, file):
    """
    show all tables archived for DATE, or stored in FILE
    """
    print('  list::0', verbose=2)
    if not (date or file):
        print('  list::1', verbose=2)
        files = []
        files = STORAGE_1.glob('*')
        files.extend(STORAGE_2.glob('*'))
        files.sort(key=lambda p: p.filename)
        for file in files:
            echo(file)
    else:
        print('  list::3', verbose=2)
        if not date:
            found = [file]
        else:
            found = STORAGE_1.glob('%s*' % date)
            if not found:
                print('  list::4', verbose=2)
                found = STORAGE_2.glob('%s*' % date)
                if not found:
                    abort('no files found for %s' % date)
        print('  list::5', verbose=2)
        for file in found:
            echo(file)
            db_names = _list(file)
            for name in db_names:
                echo('   %s' % name)
            echo()
            print('  list::6', verbose=2)


@Command(
        date=('date of archive to restore from', OPTION, None, Date),
        db=('database in archive to restore', OPTION, None),
        file=('archive file to extract from / sql file to restore from', OPTION, None, Path),
        new_db=('restore as a new database [default: restore to same database]', OPTION, None),
        all_dbs=('restore all databases found in backup', FLAG, None),
        user_files=('restore user attachments, etc.', FLAG, None),
        config_files=Spec('restore configuration files', OPTION, None, choices=['missing', 'all']),
        )
def restore(db, date, file, new_db, all_dbs, user_files, config_files):
    print('  restore::0', verbose=2)
    if (db or all_dbs) and not _user_exists('openerp') and not RESCUE:
        abort('missing openerp user in postgresql, aborting restore [use --rescue to override]')
    if (user_files or config_files) and (db or all_dbs):
        abort('cannot restore database and files in one pass')
    if date and file:
        abort('only one of DATE and FILE may be specified')
    if not (date or file):
        help('must specify a date or a file')
    all_db_names = []
    all_sql_files = []
    tgz_file = sql_file = user_file = None
    if date:
        print('  restore::1', verbose=2)
        print('    looking for %s*dbs*' % date, verbose=2)
        found = STORAGE_1.glob('%s*dbs*' % date)
        print(date.strftime('    looking for %Y-%m*dbs*'), verbose=2)
        found_user = STORAGE_1.glob(date.strftime('%Y-%m*files*'))
        if not found:
            print('  restore::2', verbose=2)
            found = STORAGE_2.glob('%s*dbs*' % date)
            found_user = STORAGE_2.glob(date.strftime('%Y-%m*files*'))
            if not found:
                abort('no files found for %s' % date)
            if (user_files or config_files) and not found_user:
                abort('user/openerp config files not found for %s' % date)
        print('found: ', found, verbose=3)
        print('found_user: ', found_user, verbose=3)
        if len(found) > 1:
            abort('should only have one match, but found %s' % ', '.join(found))
        if len(found_user) > 1:
            abort('should anly have one match, but found %s' % ', '.join(found_user))
        [file] = found
        if user_files and not found_user:
            abort('no user files found for %s' % date)
        elif user_files:
            [user_file] = found_user
        if user_files:
            file = None
    if not (file or user_file):
        abort('no files found')
    if file:
        print('  restore::3', verbose=2)
        # if a file is specified copy it to TEMP
        file.copy(TEMP)
        file = TEMP/file.filename
        file.chown(*POSTGRES_IDS)
        if file.ext in ('.tar', '.gz', '.tgz'):
            tgz_file = file
            all_db_names = _list(tgz_file)
        else:
            sql_file = file
            if db is None:
                db = _db_name_from_file(sql_file)
        print('  restore::4', verbose=2)
        with user_ids(*POSTGRES_IDS):
            print('  restore::5', verbose=2)
            TEMP.chdir()
            print('  sql_file: %s\n  tgz_file: %s' % (sql_file, tgz_file), verbose=2)
            if tgz_file:
                print('  restore::6', verbose=2)
                # at this point, we have the archive file, and we have the
                # name(s) of the database to extract in db or all_db_names
                if db:
                    print('  restore::7', verbose=2)
                    sql_file = _extract(db, tgz_file)
                else:
                    print('  restore::8', verbose=2)
                    print('extracting sql files...')
                    for _db in all_db_names:
                        all_sql_files.append(_extract(_db, tgz_file))
            # we now have sql file(s) to restore from
            if all_dbs:
                # restore everything
                _restore_all_dbs(all_sql_files, all_db_names)
            elif db:
                # restore single database
                _restore_single_db(sql_file, db, new_db)
    if config_files:
        # UNTAR = '%(tar)s -C %%(root_dir)s -xf %%(archive)s' % pg_settings
        # restore attachments/etc. and/or config files
        skip = config_files == 'missing'
        _untar(archive=user_file, root_dir=VIRTUAL_ENV, files='config/*', skip_old_files=skip)
    if user_files:
        _untar(archive=user_file, root_dir=VIRTUAL_ENV, exclude='config/*')

# helpers

def _backup(db, filename):
    pg_dump = PGDUMPCMD % dict(filename=TEMP/filename, db=db)
    print('   %s' % db, end='')
    with user_ids(*POSTGRES_IDS):
        result = Execute(pg_dump, pty=False)
    if result.returncode:
        print(' -- FAILED', file=stderr)
    else:
        print()
    if result.stdout:
        for line in result.stdout.strip().split('\n'):
            print('   %s' % line)
    if result.returncode:
        print('       %s' % pg_dump, file=stderr)
        for line in result.stderr.split('\n'):
            print('      %s' % line, file=stderr)
        print()
    return not result.returncode

def _db_name_from_file(filename, datestr=None):
    print('  _db_name_from_file::0', verbose=2)
    print('  checking', filename, 'for datestr %r' % datestr, verbose=2)
    if datestr is None:
        # probably an sql filename
        print('  stripping date...')
        return re.sub('\d{4}-\d{1,2}-\d{1,2}_', '', filename.split('.')[0])
    if filename.startswith(datestr):
        print('  old-style filename')
        # old style with leading date and '_pg91.sql' trailer
        db_name = filename[11:].rsplit('_', 1)[0].strip()
    elif filename.endswith('.sql'):
        # new style with .sql trailer
        print('  new-style filename', verbose=2)
        db_name = filename[:-4]
    return db_name

def _extract(name, archive):
    print('_extract::0', verbose=2)
    date = archive.filename[:10]
    deprecated_name = '%s_%s_pg91.sql' % (date, name)
    name = name + '.sql'
    print('_extract::1', verbose=2)
    for target in (name, deprecated_name):
        print('_extract::2', verbose=2)
        tgz_cmd = TGZEXTRACT % dict(archive=archive, target=target)
        result = Execute(tgz_cmd, pty=False)
        if result.returncode == 0:
            print('  %s extracted' % target, verbose=2)
            break
    else:
        print('_extract::3', verbose=2)
        if result.stdout:
            for line in result.stdout.strip().split('\n'):
                print(line)
        print('return code:', result.returncode, file=stderr)
        for line in result.stderr.split('\n'):
            print(line, file=stderr)
        raise SystemExit(result.returncode)
    print('_extract::4', verbose=2)
    return Path(target)

def _get_dbs_from_postgres():
    result = _psql('--list --tuple')
    dbs = []
    for line in result.split('\n'):
        db = line.split('|', 1)[0].strip()
        if db and db != 'template0':
            # template0 is special, and cannot be accessed
            dbs.append(db)
    if not dbs:
        error('FAILED: %r' % result)
        raise SystemExit('no databases found!')
    return dbs

def _get_dbs_from_tar(tar_file):
    result = _psql('--list --tuple')
    dbs = []
    for line in result.split('\n'):
        db = line.split('|', 1)[0].strip()
        if db and db != 'template0':
            # template0 is special, and cannot be accessed
            dbs.append(db)
    if not dbs:
        error('FAILED: %r' % result)
        raise SystemExit('no databases found!')
    return dbs

def _get_dump_cmds():
    print('gdc::0', verbose=2)
    global PGDUMPCMD, PGDUMPALLCMD
    # get server version
    text = _psql("""-c "select current_setting('server_version_num')" --tuples-only""")
    print('gdc::1 -> %r' % (text, ), verbose=2)
    version = 'v' + text.strip()[:-2]
    print('gdc::2', verbose=2)
    PGDUMPCMD %= pg_settings[version]
    print('gdc::3', verbose=2)
    PGDUMPALLCMD %= pg_settings[version]
    print('gdc::4', verbose=2)
    print('commands are:\n%r\n%r' % (PGDUMPCMD, PGDUMPALLCMD), verbose=3)

def _get_backup_filename():
    """
    get the location for today's backup
    """
    # M-W-F backups go to STORAGE_1
    # T-TH-Sa backups go to STORAGE_2
    # Su and monthly alternate between the two
    #   Sunday selection is based on odd/even of date.toordinal()
    #   month selection is based on odd/even of month number
    #
    # isoweekday has Sunday as 0 XXX incorrect, and now using an Enum
    #
    # first priority is month-end
    # then sundays
    # then other days
    #
    locations = [STORAGE_1, STORAGE_2]
    tomorrow = TODAY.replace(delta_day=1)
    weekday = Weekday(TODAY)
    if tomorrow.day == 1:
        # month end!
        i = TODAY.month%2
        dbs_name = locations[i] / TODAY.strftime('%Y-%m-%d_End_dbs')
        files_name = locations[i] / TODAY.strftime('%Y-%m_files')
    elif weekday is Weekday.SUNDAY:
        i = TODAY.toordinal() % 2
        dbs_name = locations[i] / TODAY.strftime('%Y-%m-%d_Sun_dbs')
        files_name = locations[i] / TODAY.strftime('%Y-%m_files')
    else:
        # some other day!
        i = weekday.value % 2
        dbs_name = locations[i] / TODAY.strftime('%Y-%m-%d_%a_dbs')
        files_name = locations[i] / TODAY.strftime('%Y-%m_files')
    print('filenames:\n   %s\n   %s' % (dbs_name, files_name), verbose=2)
    return dbs_name, files_name

def _list(archive):
    print('  _list::1', verbose=2)
    print('checking archive', archive.filename)
    if 'pg91' in archive:
        tables = True
    else:
        tables = False
    datestr = archive.filename[:11]
    tgz_cmd = TARDISPLAY % dict(target=archive)
    result = Execute(tgz_cmd, pty=False)
    dbs = []
    if result.stdout:
        for line in result.stdout.strip().split('\n'):
            if tables:
                db_name = _db_name_from_file(line, datestr)
            else:
                db_name = line
            if db_name:
                dbs.append(db_name)
    if result.returncode:
        print('FAILED: %s' % tgz_cmd, file=stderr)
        for line in result.stderr.split('\n'):
            print('   %s' % line, file=stderr)
        raise SystemExit(result.returncode)
    print('  found: ', ', '.join(dbs))
    return dbs

def _psql(cmd):
    cmd = '%s %s' % (PSQLCMD, cmd)
    print(verbose=2)
    print(cmd, verbose=2)
    with user_ids(*POSTGRES_IDS):
        result = Execute(cmd, pty=False)
    if result.returncode:
        lines = []
        if result.returncode != -1:
            lines.append('FAILED: <%d> %s' % (result.returncode, cmd))
        for line in result.stderr.split('\n'):
            lines.append('   %s' % line)
        if result.returncode != -1:
            raise Exception('\n'.join(lines))
    return result.stdout

def _remove_excess(fq_file):
    """
    keep one copy of each day's backup
    """
    # each backup location should have one monthly backup, one weekly backup,
    # and one each of either MWF or TThSa -- so whichever one we just made, we
    # can delete its older copy
    #
    # fq_file includes the date and type portion of the filename
    dirname = fq_file.dirname
    type = fq_file.split('_')[1]        # type is End, Sun, Mon, Tue, Wed, Thu, Fri, or Sat
    found = dirname.glob('*%s*' % type)
    try:
        for f in found:
            if not f.startswith(fq_file):
                print('removing', f)
                f.unlink()
    except:
        error(sys.exc_info())
        raise

def _restore_all_dbs(sql_files, dbs):
    print('  _restore_all::0', verbose=2)
    if len(sql_files) != len(dbs):
        print('sql files:\n  ', '\n   '.join(sql_files), file=stderr)
        print('db names:\n  ', '\n   '.join(dbs), file=stderr)
        abort('number of files vs number of databases differ')
    print('  _restore_all::1', verbose=2)
    for db in dbs:
        # some databases cannot be dropped
        if db in ('_roles_etc', 'postgres', 'template1'):
            continue
        print('dropping', db)
        _psql('-c "DROP DATABASE IF EXISTS %s;"' % db)
    log_file = Path('restore_all.log')
    print('  _restore_all::3', verbose=2)
    print('restoring globals... ', end='')
    _psql('--log-file %s --echo-all --file _roles_etc.sql' % log_file)
    print('success\nrestoring postgres... ', end='')
    postgres_file = sql_files[dbs.index('postgres')]
    if 'postgres' not in postgres_file:
        abort('\nlogic error: "postgres" table not in "%s"' % postgres_file)
    _psql('--log-file %s --echo-all --file %s postgres' % (log_file, postgres_file))
    print('sucess\nrestoring template1... ', end='')
    template1_file = sql_files[dbs.index('template1')]
    if 'template1' not in template1_file:
        abort('\nlogic error: "template1" table not in "%s"' % template1_file)
    _psql('--log-file %s --echo-all --file %s template1' % (log_file, template1_file))
    print('success')
    errors = []
    for db, sql_file in zip(dbs, sql_files):
        if db in ('_roles_etc', 'template1', 'postgres'):
            continue
        print('restoring %s... ' % db, end='')
        _psql('''-c "CREATE DATABASE %s TEMPLATE template1 ENCODING 'unicode';"''' % db)
        try:
            error = None
            print('  _restore_all::4', verbose=2)
            _psql(
                    '--log-file %(log)s --echo-all --file %(sql)s %(db_name)s'
                    % dict(sql=sql_file, db_name=db, log=log_file),
                    )
            print('  _restore_all::5', verbose=2)
            # TODO: find out if changing the owner is necessary
            _psql('-c "ALTER DATABASE %s OWNER TO openerp;"' % db)
        except Exception as exc:
            print('FAILED')
            errors.append(exc)
        else:
            print('success')
    with user_ids(0, 0):
        print('  _restore_all::6', verbose=2)
        dest_file = START_DIR/log_file.filename
        if dest_file.exists():
            print('  _restore_all::7', verbose=2)
            dest_file.remove()
        print('  _restore_all::8', verbose=2)
        log_file.chown(*ACTUAL_IDS)
        print('  _restore_all::9', verbose=2)
        log_file.move(dest_file)
    if errors:
        print('\nerrors', file=stderr)
        for error in errors:
            print('------', file=stderr)
            print(error, file=stderr)
        print('------', file=stderr)
        abort('errors encountered')
        # possibly examine the log file for errors here

def _restore_single_db(sql_file, db, new_db):
    if new_db is None:
        new_db = db
    if not new_db.startswith('test_'):
        print('  _restore_single::1', verbose=2)
        current_dbs = _get_dbs_from_postgres()
        if new_db in current_dbs:
            answer = get_response('\n%s already exists -- [r]ename or [o]verwrite?' % new_db)
            if answer == 'overwrite':
                if not get_response('\nthis cannot be undone -- are you sure?'):
                    raise SystemExit('database restore aborted')
                # drop...
                _psql('-c "DROP DATABASE %s;"' % new_db)
            elif answer == 'rename':
                print('\ncurrent databases:', verbose=0)
                for db in current_dbs:
                    print('  ', db, verbose=0)
                new_name = get_response(
                        '\nnew database name:',
                        validate=lambda name: name not in current_dbs,
                        type=lambda name: name,
                        retry='that name is also in use, please choose another',
                        )
                # rename...
                _psql('-c "ALTER DATABASE %s RENAME TO %s;"' % (new_db, new_name))
            else:
                raise Exception('unable to process response of %r' % answer)
    else:
        print('  _restore_single::2', verbose=2)
        # overwrite test_ databases
        _psql('-c "DROP DATABASE IF EXISTS %s;"' % new_db)
    # at this point we are good to restore...
    #
    # (re)create the new database
    log_file = Path(new_db+'.log')
    print('  _restore_single::3', verbose=2)
    _psql('''-c "CREATE DATABASE %s TEMPLATE template1 ENCODING 'unicode';"''' % new_db)
    try:
        error = None
        print('  _restore_single::4', verbose=2)
        _psql(
                '--log-file %(log)s --echo-all --file %(sql)s %(db_name)s'
                % dict(sql=sql_file, db_name=new_db, log=log_file),
                )
        print('  _restore_single::5', verbose=2)
        _psql('-c "ALTER DATABASE %s OWNER TO openerp;"' % new_db)
    except Exception as exc:
        error = exc
    with user_ids(0, 0):
        print('  _restore_single::6', verbose=2)
        dest_file = START_DIR/new_db+'.log'
        if dest_file.exists():
            print('  _restore_single::7', verbose=2)
            dest_file.remove()
        print('  _restore_single::8', verbose=2)
        log_file.chown(*ACTUAL_IDS)
        print('  _restore_single::9', verbose=2)
        log_file.move(dest_file)
    if error:
        raise error
    # possibly examine the log file for errors here

def _tgz_dbs(source_path, target_path, id=None):
    if id is None:
        target = target_path + '.tar.gz'
    else:
        target = target_path + '_%s.tar.gz' % (id, )
    tgz_cmd = TARARCHIVE % dict(target_name=target, file_list=' '.join(source_path.listdir()))
    print('\narchiving and compressing . . .')
    print('   %s' % tgz_cmd, verbose=2)
    result = Execute(tgz_cmd, cwd=source_path, pty=False, GZIP="--rsyncable")
    if result.stdout:
        for line in result.stdout.split('\n'):
            print('   %s' % line)
    if result.returncode:
        print('FAILED: %s' % tgz_cmd, file=stderr)
        for line in result.stderr.split('\n'):
            print('        %s' % line, file=stderr)
        raise SystemExit(result.returncode)
    return target

def _tar_files(files_name, id=None):
    # static files/locations are in $VIRTUAL_ENV/var/openerp/fnxfs
    # location of dynamic store is in openerp at
    #   ir.config_parameter:ir_attachment.location
    #
    targets = ['config', 'var/openerp/fnxfs', 'ws']
    conn = get_connection(hostname=OEHOST, database=OEDATA, login=OEUSER, password=OEPSWD)
    location = get_records(conn, 'ir.config_parameter', domain=[('key','=','ir_attachment.location')])
    if location:
        location = location[0].value
        if location.startswith('file://'):
            location = Path(location[7:])
            if location[0] not in '/\\':
                # add openerp directory to location
                location = Path('openerp') / location
            targets.append(location)
    # file names collected, now generate tgz file name, and back them up
    if id is None:
        target = files_name + '.tar'
    else:
        target = files_name + '_%s.tar' % (id, )
    tar_cmd = TARFILEARCHIVE % dict(target_name=target, file_list=' '.join(targets))
    print('\narchiving. . .')
    print('   %s' % tar_cmd, verbose=2)
    result = Execute(tar_cmd, cwd=VIRTUAL_ENV, pty=False)
    if result.stdout:
        for line in result.stdout.split('\n'):
            print('   %s' % line)
    if result.returncode:
        print('FAILED: %s' % tar_cmd, file=stderr)
        for line in result.stderr.split('\n'):
            print('        %s' % line, file=stderr)
        raise SystemExit(result.returncode)
    return target

def _untar(archive, root_dir, files=None, exclude=None, skip_old_files=False):
    untar_cmd = UNTAR % dict(root_dir=root_dir, archive=archive)
    if files:
        untar_cmd += ' --wildcards %s' % files
    if exclude:
        untar_cmd += '  --wildcards --exclude %s' % exclude
    if skip_old_files:
        untar_cmd += ' --skip-old-files'
    print('\nextracting with %r' % untar_cmd)
    result = Execute(untar_cmd, pty=False)
    if result.stdout:
        for line in result.stdout.split('\n'):
            print('   %s' % line)
    if result.returncode:
        print('FAILED: %s' % untar_cmd, file=stderr)
        for line in result.stderr.split('\n'):
            print('        %s' % line, file=stderr)
        raise SystemExit(result.returncode)

def _user_exists(user):
    output = _psql('-c "select rolname from pg_authid;"').split('\n')
    result = False
    for i, line in enumerate(output[2:], start=1):
        print(i, line)
        if line.strip() == user:
            result = True
    return result


class Weekday(Enum):
    """
    Days of the week, ISO numbered
    """
    MONDAY = 1
    TUESDAY = 2
    WEDNESDAY = 3
    THURSDAY = 4
    FRIDAY = 5
    SATURDAY = 6
    SUNDAY = 7

    @classmethod
    def from_date(cls, date):
        return cls(date.isoweekday())

Main()
