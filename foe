#!/usr/local/bin/suid-python --virtualenv
"""
Utility to copy postgres/openerp backups to the network, and
copy FIS data from the network.
"""
from __future__ import print_function
from antipathy import Path
from scription import *
import os, sys

@Script()
def main():
    global config
    config = OrmFile('%s/config/fnx.ini' % os.environ['VIRTUAL_ENV'], types={'_path':Path})

@Command()
def info():
    "show network and local settings"
    if config.network.role == 'master':
        storage1_src = config.postgres.storage1
        storage2_src = config.postgres.storage2
        storage1_dst = config.network.storage1
        storage2_dst = config.network.storage2
        host = config.network.slave
        echo('\nbackups will be copied from\n  %s\nto\n  %s:%s' % (storage1_src, host, storage1_dst))
        if storage2_src:
            echo('\nand from\n  %s\nto\n  %s:%s' % (storage2_src, host, storage2_dst,))
    elif config.network.role == 'slave':
        storage1_src = config.network.storage1
        storage2_src = config.network.storage2
        storage1_dst = config.postgres.storage1
        storage2_dst = config.postgres.storage2
        host = config.network.master
        echo('\nbackups will be copied from\n  %s:%s\nto\n  %s' % (host, storage1_src, storage1_dst,))
        if storage2_src:
            echo('\n\nand from\n  %s:%s\nto\n  %s' % (host, storage2_src, storage2_dst))
    if OrmSection.get(config.network, 'fis_data_host') is None:
        echo('\n\ncanonical fis data host not configured')
    host = config.network.fis_data_host
    path = config.network.fis_data_path
    pre = config.network.fis_data_prefix
    local_path = config.network.fis_data_local_path
    echo('\nFIS %r data files will be copied from\n  %s:%s\nto\n  %s' % (pre, host, path, local_path))
    if config.postgres.storage1 == config.postgres.storage2 or not config.postgres.storage2:
        echo('\nCurrent backups:\n  %s' % '\n  '.join(sorted(Path(config.postgres.storage1).listdir())))
    else:
        echo('\nCurrent storage1 backups:\n  %s' % '\n  '.join(sorted(Path(config.postgres.storage1).listdir())))
        echo('\nCurrent storage2 backups:\n  %s' % '\n  '.join(sorted(Path(config.postgres.storage2).listdir())))

@Command(
        remove=('remove excess backups', FLAG),
        latest=('only get last backup', FLAG),
        info=('show paths', FLAG),
        )
def backups(remove, latest, info):
    """
    copy backup from master to slave

    local files live in:
    - postgres.storage1
    - postgres.storage2
    network files live in:
    - network.storage1
    - network.storage2
    and the operation (send vs receive) is determined by:
    - network.role
    """
    verbosity = not info
    if config.network.role == 'master':
        storage1_src = config.postgres.storage1
        storage2_src = config.postgres.storage2
        storage1_dst = config.network.storage1
        storage2_dst = config.network.storage2
        host = config.network.slave
        to_remote = True
        print('moving backups from\n  %s\nto\n  %s:%s\nand from\n  %s\nto\n  %s:%s' % (
            storage1_src, host, storage1_dst,
            storage2_src, host, storage2_dst,
            ),
            verbose=verbosity,
            )
    elif config.network.role == 'slave':
        storage1_src = config.network.storage1
        storage2_src = config.network.storage2
        storage1_dst = config.postgres.storage1
        storage2_dst = config.postgres.storage2
        host = config.network.master
        to_remote = False
        if latest:
            storage1_src /= '*pg91*'
            storage2_src /= '*pg91*'
        print('copying backups from\n  %s:%s\nto\n  %s\nand from\n  %s:%s\nto\n  %s' % (
            host, storage1_src, storage1_dst,
            host, storage2_src, storage2_dst,
            ),
            verbose=verbosity,
            )
    else:
        help('invalid network role: %r' % config.network.role)
    if info:
        return Exit.Success
    output = []
    command, job = rsync(storage1_src, host, storage1_dst, to_remote)
    if job.returncode or job.stderr:
        output.extend(['*' * 50, command, '-' * 50, job.stdout, '-' * 50, job.stderr])
    if storage2_src:
        command, job = rsync(storage2_src, host, storage2_dst, to_remote)
        if job.returncode or job.stderr:
            output.extend(['*' * 50, command, '-' * 50, job.stdout, '-' * 50, job.stderr])
        if output:
            output.append('*' * 50)
    if config.network.role == 'slave' and remove:
        _remove_excess(config.postgres.storage1, config.postgres.daily_limit)
        _remove_excess(config.postgres.storage2, config.postgres.monthly_limit)
    if output:
        error('\n'.join(output))
        return Exit.Unknown


@Command(
        complete=('copy all files, or just the ones mirrored to OpenERP?', FLAG),
        )
def fis(complete):
    """
    update FIS files master

    copy from network.fis_data_host/path to network.fis_data_local_path
    """
    if OrmSection.get(config.network,'fis_data_host') is None:
        abort('canonical fis data host not configured')
    host = config.network.fis_data_host
    path = config.network.fis_data_path
    pre = config.network.fis_data_prefix
    local_path = config.network.fis_data_local_path
    if complete:
        files = (
                '{path}/{pre}???? {path}/{pre}????? {path}/{pre}?????? '
                '{path}/{pre}????M {path}/{pre}?????M {path}/{pre}??????M '
                '{path}/{pre}????.txt {path}/{pre}?????.txt {path}/{pre}??????.txt '
                ).format(path=path, pre=pre).split()
    else:
        files = ' '.join([
            '{path}/{pre}{f} {path}/{pre}{f}M {path}/{pre}{f}.txt'.format(path=path, pre=pre, f=f)
            for f in config.network.fis_openerp_files.split()
            ]).split()
        files.extend(
            ' '.join([
            '{path}/{pre}{f}'.format(path=path, pre=pre, f=f)
            for f in config.network.fis_openerp_extra_files.split()
            ]).split()
            )
        # XXX - dirty hack to get weird file
        if pre == 'O':
            files.append('{path}/COPERM'.format(path=path))
    output = []
    try:
        print('calling rsync')
        command, job = rsync(' :'.join(files), host, local_path)
    except RSyncFailure as exc:
        raise SystemExit(exc.job.returncode)
    output.extend([command, job.stdout, job.stderr])
    command = 'chown -R openerp: %s' % (local_path, )
    print(command, verbose=1)
    job = Execute(command, timeout=60*15)
    output.extend([command, job.stderr, job.stdout])
    print(job.stdout, verbose=1)
    if job.returncode:
        error('\n-----------------\n'.join(output))
        raise SystemExit(job.returncode)
    print('chmod 440 %s/*' % config.network.fis_data_local_path, verbose=1)
    config.network.fis_data_local_path.chmod(0o440, '*')


class RSyncFailure(Exception):
    "raised when rsync command fails"
    job = None
    def __init__(self, job, commandline):
        super(RSyncFailure, self).__init__()
        self.job = job
        self.commandline = commandline


def rsync(files, host, dst_path, to_remote=False):
    """copies files to dst_path

    to_remote == True -> local files are sent to host:dst_path
                False -> host:files are sent to dst_path
    dst_path -> directory to copy to
    host -> IP/DNS name of remote host
    files -> full path of files to copy
    """
    if to_remote:
        command = (
                'rsync -a %s root@%s:%s'
                % (' '.join(files), host, dst_path)
                )
    else:
        command = (
                'rsync -a root@%s:%s %s/'
                % (host, files, dst_path)
                )
    if script_verbosity:
        command += ' -v'
    print(command)
    try:
        job = Execute(command, pty=True, password=config.network.pw, password_timeout=300, timeout=3600*5)
        print(job.stdout)
        print(job.stderr)
    except ExecuteError:
        cls, exc, tb = sys.exc_info()
        raise RSyncFailure(job=exc.process, commandline=command)
    return command, job

def _remove_excess(storage, limit):
    """
    keep LIMIT days worth of our backups
    """
    print('removing excess backups')
    print('  allowing %d days in %s' % (limit, storage), verbose=2)
    found_dbs = storage.glob('*_pg91.tar.gz')
    found_dbs.sort(reverse=True)
    found_bin = storage.glob('*_files.tar.gz')
    found_bin.sort(reverse=True)
    for target in found_dbs[limit:]:
        print('    removing %s' % target, verbose=2)
        target.remove()
    for target in found_bin[limit:]:
        print('    removing %s' % target, verbose=2)
        target.remove()


Run()
